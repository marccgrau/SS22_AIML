{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in ./venv/lib/python3.9/site-packages (1.2.10)\r\n",
      "Requirement already satisfied: snuggs>=1.4.1 in ./venv/lib/python3.9/site-packages (from rasterio) (1.4.7)\r\n",
      "Requirement already satisfied: attrs in ./venv/lib/python3.9/site-packages (from rasterio) (21.4.0)\r\n",
      "Requirement already satisfied: click-plugins in ./venv/lib/python3.9/site-packages (from rasterio) (1.1.1)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from rasterio) (60.2.0)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from rasterio) (1.22.3)\r\n",
      "Requirement already satisfied: cligj>=0.5 in ./venv/lib/python3.9/site-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: affine in ./venv/lib/python3.9/site-packages (from rasterio) (2.3.1)\r\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.9/site-packages (from rasterio) (2021.10.8)\r\n",
      "Requirement already satisfied: click>=4.0 in ./venv/lib/python3.9/site-packages (from rasterio) (8.1.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in ./venv/lib/python3.9/site-packages (from snuggs>=1.4.1->rasterio) (3.0.8)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '/home/mcgrau/PycharmProjects/SS22_AIML/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Requirement already satisfied: wandb in ./venv/lib/python3.9/site-packages (0.12.14)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./venv/lib/python3.9/site-packages (from wandb) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.13.0 in ./venv/lib/python3.9/site-packages (from wandb) (1.16.0)\r\n",
      "Requirement already satisfied: pathtools in ./venv/lib/python3.9/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (1.5.10)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (3.1.27)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (2.27.1)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./venv/lib/python3.9/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: setproctitle in ./venv/lib/python3.9/site-packages (from wandb) (1.2.3)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./venv/lib/python3.9/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: protobuf>=3.12.0 in ./venv/lib/python3.9/site-packages (from wandb) (3.20.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./venv/lib/python3.9/site-packages (from wandb) (8.1.2)\r\n",
      "Requirement already satisfied: PyYAML in ./venv/lib/python3.9/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./venv/lib/python3.9/site-packages (from wandb) (1.0.8)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '/home/mcgrau/PycharmProjects/SS22_AIML/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning library\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/home/mcgrau/PycharmProjects/SS22_AIML/models'\n",
    "test_directory = '/home/mcgrau/PycharmProjects/SS22_AIML/data/testset'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"AnnualCrop\",\n",
    "    \"Forest\",\n",
    "    \"HerbaceousVegetation\",\n",
    "    \"Highway\",\n",
    "    \"Industrial\",\n",
    "    \"Pasture\",\n",
    "    \"PermanentCrop\",\n",
    "    \"Residential\",\n",
    "    \"River\",\n",
    "    \"SeaLake\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "27000"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change this to your eurosat path\n",
    "eurosat_dir = \"ds/images/remote_sensing/otherDatasets/sentinel_2/tif\"\n",
    "samples = glob.glob(os.path.join(eurosat_dir, \"*\", \"*.tif\"))\n",
    "len(samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PermanentCrop\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 111\n",
    "sample = samples[sample_idx]\n",
    "label = sample.split('/')[-1].split('_')[0]\n",
    "print(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] notebook with cuda computation enabled\n"
     ]
    }
   ],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled[2, 2, 2, 2]\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 20 15:48:00 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   38C    P0    20W /  N/A |     13MiB /  7982MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1716      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A      3610      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    \"\"\"Create own dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, transform=False):\n",
    "        self.eurosat_dir = \"ds/images/remote_sensing/otherDatasets/sentinel_2/tif\"\n",
    "        self.samples = glob.glob(os.path.join(self.eurosat_dir, \"*\", \"*.tif\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        input = self.samples[idx]\n",
    "        label = input.split('/')[-1].split('_')[0]\n",
    "        label = class_to_idx[label]\n",
    "        with rio.open(input, \"r\") as d:\n",
    "          image = d.read([1,2,3,4,5,6,7,8,9,11,12,13]).astype(int)\n",
    "          image = reshape_as_image(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = transforms.ToTensor()(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "trainData = SatelliteDataset(transform = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"ResNet\",\n",
    "    \"ResNet18_Weights\",\n",
    "    \"resnet18\"\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        #_log_api_usage_once(self)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(12, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.logsoftmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2])\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 20 15:48:03 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   38C    P0    21W /  N/A |   1038MiB /  7982MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1716      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A      3610      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A      8686      C   ...SS22_AIML/venv/bin/python     1025MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "nll_loss = nn.NLLLoss()\n",
    "nll_loss = nll_loss.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "mini_batch_size = 2000\n",
    "train_loader = DataLoader(trainData, batch_size=mini_batch_size, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33munisg-ds-nlp\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.14"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/mcgrau/PycharmProjects/SS22_AIML/wandb/run-20220420_154804-2jelatrc</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/unisg-ds-nlp/uncategorized/runs/2jelatrc\" target=\"_blank\">twilight-leaf-18</a></strong> to <a href=\"https://wandb.ai/unisg-ds-nlp/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20220420-13:49:32] epoch: 0 train-loss: 1.0853094926902227\n",
      "[LOG 20220420-13:50:48] epoch: 1 train-loss: 0.40037586859294344\n",
      "[LOG 20220420-13:52:04] epoch: 2 train-loss: 0.3075839174645288\n",
      "[LOG 20220420-13:53:20] epoch: 3 train-loss: 0.22605963796377182\n",
      "[LOG 20220420-13:54:37] epoch: 4 train-loss: 0.17984807171991893\n",
      "[LOG 20220420-13:55:53] epoch: 5 train-loss: 0.1486909565116678\n",
      "[LOG 20220420-13:57:10] epoch: 6 train-loss: 0.116673046456916\n",
      "[LOG 20220420-13:58:27] epoch: 7 train-loss: 0.08580646397812026\n",
      "[LOG 20220420-13:59:44] epoch: 8 train-loss: 0.06971496263785022\n",
      "[LOG 20220420-14:01:00] epoch: 9 train-loss: 0.05641913839748928\n",
      "[LOG 20220420-14:02:17] epoch: 10 train-loss: 0.03769051789173058\n",
      "[LOG 20220420-14:03:34] epoch: 11 train-loss: 0.062223504430481365\n",
      "[LOG 20220420-14:04:51] epoch: 12 train-loss: 0.04259090404957533\n",
      "[LOG 20220420-14:06:07] epoch: 13 train-loss: 0.026722495776734183\n",
      "[LOG 20220420-14:07:25] epoch: 14 train-loss: 0.025471508902098452\n",
      "[LOG 20220420-14:08:43] epoch: 15 train-loss: 0.02477494933243309\n",
      "[LOG 20220420-14:10:00] epoch: 16 train-loss: 0.030493172351270914\n",
      "[LOG 20220420-14:11:16] epoch: 17 train-loss: 0.04349858100925173\n",
      "[LOG 20220420-14:12:31] epoch: 18 train-loss: 0.022361705545336008\n",
      "[LOG 20220420-14:13:46] epoch: 19 train-loss: 0.011498446609558803\n",
      "[LOG 20220420-14:15:01] epoch: 20 train-loss: 0.015682715822809508\n",
      "[LOG 20220420-14:16:15] epoch: 21 train-loss: 0.016657755227892528\n",
      "[LOG 20220420-14:17:30] epoch: 22 train-loss: 0.013546856785459178\n",
      "[LOG 20220420-14:18:44] epoch: 23 train-loss: 0.009939197118261031\n",
      "[LOG 20220420-14:19:58] epoch: 24 train-loss: 0.015713107406294773\n",
      "[LOG 20220420-14:21:12] epoch: 25 train-loss: 0.023468830423163518\n",
      "[LOG 20220420-14:22:27] epoch: 26 train-loss: 0.03160945578877415\n",
      "[LOG 20220420-14:23:42] epoch: 27 train-loss: 0.012971021002158523\n",
      "[LOG 20220420-14:24:57] epoch: 28 train-loss: 0.009958031088379877\n",
      "[LOG 20220420-14:26:13] epoch: 29 train-loss: 0.012453487275966577\n",
      "[LOG 20220420-14:27:29] epoch: 30 train-loss: 0.02605311685640897\n",
      "[LOG 20220420-14:28:45] epoch: 31 train-loss: 0.019333444336163148\n",
      "[LOG 20220420-14:30:01] epoch: 32 train-loss: 0.007834227290004492\n",
      "[LOG 20220420-14:31:17] epoch: 33 train-loss: 0.004098979473513152\n",
      "[LOG 20220420-14:32:33] epoch: 34 train-loss: 0.005281293382202941\n",
      "[LOG 20220420-14:33:49] epoch: 35 train-loss: 0.004944851888077599\n",
      "[LOG 20220420-14:35:05] epoch: 36 train-loss: 0.004875471154394161\n",
      "[LOG 20220420-14:36:20] epoch: 37 train-loss: 0.001148700518699895\n",
      "[LOG 20220420-14:37:35] epoch: 38 train-loss: 0.0014955425743080144\n",
      "[LOG 20220420-14:38:50] epoch: 39 train-loss: 0.0009980499630078807\n",
      "[LOG 20220420-14:40:05] epoch: 40 train-loss: 0.0005095589398739061\n",
      "[LOG 20220420-14:41:19] epoch: 41 train-loss: 0.0001601499316166155\n",
      "[LOG 20220420-14:42:34] epoch: 42 train-loss: 9.766026050783694e-05\n",
      "[LOG 20220420-14:43:48] epoch: 43 train-loss: 6.957387579729714e-05\n",
      "[LOG 20220420-14:45:02] epoch: 44 train-loss: 5.3886824129481935e-05\n",
      "[LOG 20220420-14:46:16] epoch: 45 train-loss: 4.9748635969340936e-05\n",
      "[LOG 20220420-14:47:31] epoch: 46 train-loss: 4.314325035790846e-05\n",
      "[LOG 20220420-14:48:47] epoch: 47 train-loss: 4.0912345087105806e-05\n",
      "[LOG 20220420-14:50:03] epoch: 48 train-loss: 3.8154251602203916e-05\n",
      "[LOG 20220420-14:51:18] epoch: 49 train-loss: 3.5029435561487586e-05\n",
      "[LOG 20220420-14:52:34] epoch: 50 train-loss: 3.301926127668204e-05\n",
      "[LOG 20220420-14:53:50] epoch: 51 train-loss: 3.264863400025726e-05\n",
      "[LOG 20220420-14:55:06] epoch: 52 train-loss: 2.9376683024955647e-05\n",
      "[LOG 20220420-14:56:21] epoch: 53 train-loss: 2.770312091472858e-05\n",
      "[LOG 20220420-14:57:37] epoch: 54 train-loss: 2.9076546265319587e-05\n",
      "[LOG 20220420-14:58:55] epoch: 55 train-loss: 2.7970326430347215e-05\n",
      "[LOG 20220420-15:00:18] epoch: 56 train-loss: 2.593082535895519e-05\n",
      "[LOG 20220420-15:01:47] epoch: 57 train-loss: 2.652284664301468e-05\n",
      "[LOG 20220420-15:03:13] epoch: 58 train-loss: 2.7205496995260807e-05\n",
      "[LOG 20220420-15:04:43] epoch: 59 train-loss: 2.4847029505638473e-05\n",
      "[LOG 20220420-15:06:11] epoch: 60 train-loss: 2.487502998909414e-05\n",
      "[LOG 20220420-15:07:33] epoch: 61 train-loss: 2.3627551724660278e-05\n",
      "[LOG 20220420-15:08:56] epoch: 62 train-loss: 2.3067139019466204e-05\n",
      "[LOG 20220420-15:10:29] epoch: 63 train-loss: 2.0098745153518394e-05\n",
      "[LOG 20220420-15:11:49] epoch: 64 train-loss: 2.194767850076979e-05\n",
      "[LOG 20220420-15:13:08] epoch: 65 train-loss: 2.153277780182959e-05\n",
      "[LOG 20220420-15:14:28] epoch: 66 train-loss: 1.8636829996207132e-05\n",
      "[LOG 20220420-15:15:47] epoch: 67 train-loss: 1.978232629491166e-05\n",
      "[LOG 20220420-15:17:14] epoch: 68 train-loss: 1.7854675856402275e-05\n",
      "[LOG 20220420-15:18:35] epoch: 69 train-loss: 1.9144596080877818e-05\n",
      "[LOG 20220420-15:19:53] epoch: 70 train-loss: 1.6138864663974217e-05\n",
      "[LOG 20220420-15:21:15] epoch: 71 train-loss: 1.6292179225274595e-05\n",
      "[LOG 20220420-15:22:37] epoch: 72 train-loss: 1.5446195902768523e-05\n",
      "[LOG 20220420-15:23:59] epoch: 73 train-loss: 1.7020555657966596e-05\n",
      "[LOG 20220420-15:25:23] epoch: 74 train-loss: 1.590335523360409e-05\n",
      "[LOG 20220420-15:26:48] epoch: 75 train-loss: 1.5120015632419381e-05\n",
      "[LOG 20220420-15:28:10] epoch: 76 train-loss: 1.4623430485828845e-05\n",
      "[LOG 20220420-15:29:34] epoch: 77 train-loss: 1.4218893479015346e-05\n",
      "[LOG 20220420-15:31:01] epoch: 78 train-loss: 1.4607676933207716e-05\n",
      "[LOG 20220420-15:32:23] epoch: 79 train-loss: 1.4505757267865452e-05\n",
      "[LOG 20220420-15:33:46] epoch: 80 train-loss: 1.434716692269181e-05\n",
      "[LOG 20220420-15:35:08] epoch: 81 train-loss: 1.2747173319179897e-05\n",
      "[LOG 20220420-15:36:30] epoch: 82 train-loss: 1.3942844686555742e-05\n",
      "[LOG 20220420-15:37:54] epoch: 83 train-loss: 1.2460178303237107e-05\n",
      "[LOG 20220420-15:39:17] epoch: 84 train-loss: 1.1997699857602129e-05\n",
      "[LOG 20220420-15:40:38] epoch: 85 train-loss: 1.4125410611346264e-05\n",
      "[LOG 20220420-15:41:58] epoch: 86 train-loss: 1.161065795583584e-05\n",
      "[LOG 20220420-15:43:17] epoch: 87 train-loss: 1.257217575455018e-05\n",
      "[LOG 20220420-15:44:38] epoch: 88 train-loss: 1.2150741440564161e-05\n",
      "[LOG 20220420-15:46:00] epoch: 89 train-loss: 1.1168616051041422e-05\n",
      "[LOG 20220420-15:47:22] epoch: 90 train-loss: 1.1122547415912517e-05\n",
      "[LOG 20220420-15:48:39] epoch: 91 train-loss: 1.1231287706842913e-05\n",
      "[LOG 20220420-15:49:56] epoch: 92 train-loss: 1.1140218378256708e-05\n",
      "[LOG 20220420-15:51:19] epoch: 93 train-loss: 1.0476504420304472e-05\n",
      "[LOG 20220420-15:52:40] epoch: 94 train-loss: 1.0214298007278038e-05\n",
      "[LOG 20220420-15:54:00] epoch: 95 train-loss: 1.0594918941413717e-05\n",
      "[LOG 20220420-15:55:20] epoch: 96 train-loss: 1.0460839413488948e-05\n",
      "[LOG 20220420-15:56:39] epoch: 97 train-loss: 9.604848530995827e-06\n",
      "[LOG 20220420-15:58:10] epoch: 98 train-loss: 9.917695933836512e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20220420-15:59:35] epoch: 99 train-loss: 1.0090739189243842e-05\n",
      "[LOG 20220420-16:01:00] epoch: 100 train-loss: 1.0034478464149288e-05\n",
      "[LOG 20220420-16:02:31] epoch: 101 train-loss: 9.723553960481826e-06\n",
      "[LOG 20220420-16:03:55] epoch: 102 train-loss: 9.786796194280864e-06\n",
      "[LOG 20220420-16:05:19] epoch: 103 train-loss: 9.171182065464173e-06\n",
      "[LOG 20220420-16:06:42] epoch: 104 train-loss: 8.590088132872811e-06\n",
      "[LOG 20220420-16:08:04] epoch: 105 train-loss: 8.358013993919095e-06\n",
      "[LOG 20220420-16:09:24] epoch: 106 train-loss: 8.955769447181541e-06\n",
      "[LOG 20220420-16:10:44] epoch: 107 train-loss: 8.616789987822163e-06\n",
      "[LOG 20220420-16:12:08] epoch: 108 train-loss: 7.88358342366077e-06\n",
      "[LOG 20220420-16:13:41] epoch: 109 train-loss: 8.589743401898886e-06\n",
      "[LOG 20220420-16:15:03] epoch: 110 train-loss: 8.166602648478666e-06\n",
      "[LOG 20220420-16:16:24] epoch: 111 train-loss: 8.174544843443852e-06\n",
      "[LOG 20220420-16:17:44] epoch: 112 train-loss: 7.722715638789981e-06\n",
      "[LOG 20220420-16:19:05] epoch: 113 train-loss: 7.5529806378783955e-06\n",
      "[LOG 20220420-16:20:26] epoch: 114 train-loss: 7.563972595952302e-06\n",
      "[LOG 20220420-16:21:47] epoch: 115 train-loss: 7.834672747516638e-06\n",
      "[LOG 20220420-16:23:08] epoch: 116 train-loss: 7.665046431221917e-06\n",
      "[LOG 20220420-16:24:29] epoch: 117 train-loss: 6.818210457432932e-06\n",
      "[LOG 20220420-16:25:49] epoch: 118 train-loss: 6.95947028361843e-06\n",
      "[LOG 20220420-16:27:09] epoch: 119 train-loss: 7.1586499481262374e-06\n",
      "[LOG 20220420-16:28:30] epoch: 120 train-loss: 6.8115042657674555e-06\n",
      "[LOG 20220420-16:29:51] epoch: 121 train-loss: 7.229015084573932e-06\n",
      "[LOG 20220420-16:31:13] epoch: 122 train-loss: 6.7452850609177924e-06\n",
      "[LOG 20220420-16:32:34] epoch: 123 train-loss: 7.002430655640117e-06\n",
      "[LOG 20220420-16:33:55] epoch: 124 train-loss: 6.500182995036344e-06\n",
      "[LOG 20220420-16:35:16] epoch: 125 train-loss: 6.473973469058235e-06\n",
      "[LOG 20220420-16:36:37] epoch: 126 train-loss: 6.686641427222639e-06\n",
      "[LOG 20220420-16:37:58] epoch: 127 train-loss: 6.223522437461984e-06\n",
      "[LOG 20220420-16:39:19] epoch: 128 train-loss: 6.417564366399477e-06\n",
      "[LOG 20220420-16:40:40] epoch: 129 train-loss: 5.859273837164178e-06\n",
      "[LOG 20220420-16:42:01] epoch: 130 train-loss: 5.948044385409698e-06\n",
      "[LOG 20220420-16:43:21] epoch: 131 train-loss: 6.153883370123887e-06\n",
      "[LOG 20220420-16:44:41] epoch: 132 train-loss: 5.9812542596254e-06\n",
      "[LOG 20220420-16:46:01] epoch: 133 train-loss: 6.065305212489745e-06\n",
      "[LOG 20220420-16:47:21] epoch: 134 train-loss: 5.742692857373706e-06\n",
      "[LOG 20220420-16:48:42] epoch: 135 train-loss: 5.444882974968225e-06\n",
      "[LOG 20220420-16:50:01] epoch: 136 train-loss: 5.566599546520072e-06\n",
      "[LOG 20220420-16:51:16] epoch: 137 train-loss: 5.847619344681984e-06\n",
      "[LOG 20220420-16:52:32] epoch: 138 train-loss: 5.334919835929343e-06\n",
      "[LOG 20220420-16:53:48] epoch: 139 train-loss: 5.3324609845211465e-06\n",
      "[LOG 20220420-16:55:04] epoch: 140 train-loss: 5.8629747335154595e-06\n",
      "[LOG 20220420-16:56:22] epoch: 141 train-loss: 5.193333858447399e-06\n",
      "[LOG 20220420-16:57:41] epoch: 142 train-loss: 5.1420053556025124e-06\n",
      "[LOG 20220420-16:59:00] epoch: 143 train-loss: 5.265687052867309e-06\n",
      "[LOG 20220420-17:00:20] epoch: 144 train-loss: 5.205223747647583e-06\n",
      "[LOG 20220420-17:01:40] epoch: 145 train-loss: 5.289989660793383e-06\n",
      "[LOG 20220420-17:02:59] epoch: 146 train-loss: 5.447823079001475e-06\n",
      "[LOG 20220420-17:04:20] epoch: 147 train-loss: 4.7113201162574114e-06\n",
      "[LOG 20220420-17:05:41] epoch: 148 train-loss: 4.824410487864432e-06\n",
      "[LOG 20220420-17:07:01] epoch: 149 train-loss: 4.870337891458933e-06\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "# start monitoring\n",
    "wandb.init()\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the CIFAR10 model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "\n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # push mini-batch data to computation device\n",
    "        images = images.to(device, dtype = torch.float)\n",
    "        labels = labels.to(device, dtype = torch.float)\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "\n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        labels=labels.to(torch.int64)\n",
    "\n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "\n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "\n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "\n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "\n",
    "    # set filename of actual model\n",
    "    model_name = 'resnet_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    if (epoch % 10) == 0 or epoch == (num_epochs - 1):\n",
    "      torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEcCAYAAAAsv3j+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABC9ElEQVR4nO2dfXxcVZn4v09e2jR9S9PSYt8LbSmU0tLyuqCoiNQ3kBVEBYEVRdbFV3AXV5cfIK66ur6sIPgGIrqKoEBFFNlieYdCQkPaNG0aGtKkaUPapGnaJM1knt8f906YTibJTHImc0Ke7+czn9x759xzv/fOzTxzzrnnHFFVDMMwDCOenGwLGIZhGP5hwcEwDMPohQUHwzAMoxcWHAzDMIxeWHAwDMMwemHBwTAMw+iFBQfDMAyjFxYcDMMwjF5YcDAMY1QiIjtE5N3h8n0iIuHynxLS/SnZ/m92LDh4iohMFZEN4WuXiNTHrY9JI59nXaRJ43jdcZ4bROR6h3nPF5GNrvIbDkTkSBH5nYhUi0iJiDwiIovD99ocHufZuOXPichmEfnNYD9bESkSkc/0dYyhkMl7pI/jfVpEbkvYNgf4K/C+cFOOqqqIzAdq4tIdtj6ayMu2gJEcVd0DrAAQkRuBNlX9bmK68NeOqGq0j3z+IYVjDZgmDdpVdYXD/EYs4WfzAHC3qn4k3LYcmAFsdXmshM/wM8C7VLVuCFkWhfn8uI9jDIV+75Fk9/RA9/kA6ZYB5QlJVwHrgLeLyELeCAArgdK4dInrowYrOYxAwl/QW0TkV8BGYI6IPBj+Mt0kIlfFpW2L22eziPwsTPM3ERmXRpr/CI/5tIj8VkSuS9O3Mvwlu1lE7heRwvC9L4nIxvD1hbh9LhORV0SkTETuicsuN9FPRMaLyJ/DtBtF5OI+PBaIyEMi8pKIrBeRY/pI9y0R+Ze49RtF5LpUjxPHO4AuVb0jtkFVy1T1qSTH7PX5JTteXw5xn+EdwFHAX0Tki/Glk76uaR/3zreAo8Nf9t9JOEZfn1mf989A9HFPJ9vW69jJ0iVkfwLJg0MJ8CTwJd4IALHtielGH6pqL89fwI3AdXHr84EocFrctuLw7ziCf5Cp4Xpb3D4RYEW4/nvg0lTSACcDG4ACYCJQFe+T4Nodpo29Lg7zVeCMMM2dwHUE/3jlwHhgArAJOBFYSvDLelrCufXl9yHgZ3EOk5N45QNrgaPD9fcCd/VxDicCT8StVxB84Qx4nIR8Pgd8v5/32/r7/JIdry+HhLxq4q5d7LNNek37OfZ8YGOib1+f2UD3WIr3SOI9fdi2fu6XXvsmHG9v4mcF3Evw47goPK9jw+1/Ae4AbgXOSlzP9nfBcL6sWmnk8pqqPh+3/jkRuSBcngMsAvYk7LNdVTeEyyUE/1SJJEszDXhIVTuADum/ga5XlYEE9bY7VPWZcNOvCb44u4AHVPVAmO6PwFsJAsl9qtoEoKp7B/D7PfDfIvJt4GFN8ssc+CDBF+QfJGh3zAOSpUNVXxaR6SIyEzgCaFbVHeGv4IGOM1iSfX7liccTkV7bUsz/nfR9TZMde1cf+ZxJ8s/s5fD9VO6xvu6RxHuahG19HXtNH/vG2hb2q+q++O2qGiv1tRAEmtj29yRk8UQS/1GBVSuNXA7EFkTk7cC7gNNVdTnBP2pBkn0645a7Sd7mlEqawZA4Nvxgx4rv5aeqWwnqhsuBW0TkhiT7LQe+qqorwtfxqvrPACLy9STp7wMuJPhVey9AiseJZxPBr91+6evzS3a8QTgM6thDyHIo98+BFLelui8kb28wUsCCw5uDyQS/bg+KyBLgNMf5PwN8QEQKRGQC8P5B5DFXRE4Plz8GPE3wy/2DIlIoIuOBC8JtjwMXichUABEp7i/j8Bf+QVX9NfAdgi/PRBqAc0UkJ9xnmQQcSVDllMi9wEcIAsR9aRwnnseBsXJ4G9AJIvLWhHRJP79kxxuEQ7xLsmva172zn6AKMZG+PrPhYDDHTtbeYKSAVSu9OfgrcLWIbAa2AL2K10NBVV8UkTXAK8Bugn+2fX0kHyciGxLc7gi9/kVE7iSow789/EL6JbA+TPtzVX0ZQES+ATwhIt0Ev2av6EdxGfAdEYkSVFX9c5I0dxI0EG8WkXaC+vRLRWQFQb134jlvEpGJQL2qNvR3HBF5BPikqu5MyEPD6pofiMi/AR0E7QFfSDhcX59fsuOlcq69CM8n2TVNemxV3SMiz0jw6PBfVPXL4fbSvj6zNOjrHhnoHJIeO6yS6otlwGoR+Wi43qCqp/eT3ggRVZsJzhgYEZmgqm0SPGX0JHCVqqb0iF/4z/uwqh6fScfBIMEz9g+qamW2XQzDJ6zkYKTKT0XkOIL66LtTDQwjgEU47nNgGG8GrORgGIZh9MIapA3DMIxeWHAwDMMwemHBwTAMw+jFm6ZBetq0aTp//vxsaxiGYYwYSkpKmlT1iGTvvWmCw/z583nppZfS2qe6upqjjz46Q0ZuMMeh47sfmKMrzDE9ROS1vt4b1dVKxcX9drz1AnMcOr77gTm6whzdMaqDw8GDB7OtMCDmOHR89wNzdIU5umNUB4ecHP9P3xyHju9+YI6uMEd3vGnaHAZDfn6y8db8whyHju9+kH3Hrq4u6urq6Ojo6DNNd3c3LS0twyc1CMwxOQUFBcyePTut+2xUB4e2tjamTZuWbY1+Mceh47sfZN+xrq6OiRMnMn/+fML5LnrR2dnJ2LFjh9ksPcyxN6rKnj17qKurY8GCBSnvNzLKNxnC9y8MMEcX+O4H2Xfs6Ohg6tSpfQYGgLw8/39LmmNvRISpU6f2WypMxqgODnV1Q5l/fXgwx6Hjux/44dhfYAA4dOjQMJkMHnNMzkCfbTJGdXBYuHAhdz2znYdf2Tlw4iyxcOHCbCsMiO+OvvvByHAsKBjKBHHDgzm6Y1QHh02bNvHr51/jLxv7mi43+2zatCnbCgPiu6PvfjAyHNvb27OtMCB9Oa5bt473v3/gCQyvuOIK7r//ftdaADQ0NPD+97+f9vZ2fvnLX3LNNdckTTdhwoSk21Phuuuu4/HHHx/0/vGM6uCwfPly8nJy6O72d9jy5cuXZ1thQHx39N0PRoZjYWFhthUGxGfH733ve3zqU5/KqONnP/tZvvWtbznJa1QHh5KSEnJzhEjU3+BQUlKSbYUB8d3Rdz8YGY4HDhzIaP6//vWvOeWUU1ixYgWf/vSn6e7uBoJf0l/84hdZunQpZ599Nq+//joAGzZs4LTTTuOEE07gggsuoLm5mQMHDrBt2zbe9a53sXz5clauXEl1dTUQPBF24YUXsmTJEi655BIGmstm7dq1nHjiiSxbtoxPfOITdHZ2AnD99ddz3HHHccIJJ3DdddcBcN9993H88cezfPly3va2tyXN7w9/+AOrV6/uuY47duzg7W9/O4sWLeKmm27qlT6xtHPNNdfwy1/+Egjul7POOotVq1Zx7rnn0tAQzGQ7b9489uzZw65dQ68N8b9pP4OsWrWKvOeepjsazbZKn6xatSrbCgPiu6PvfuCX401/2kTFzlaneR43cxL/7wNL+3x/8+bN3HvvvTzzzDPk5+fzmc98ht/85jdcdtllHDhwgJNOOonvf//73Hzzzdx0003ceuutXHbZZfzoRz/irLPO4oYbbuCmm27iBz/4AZdccgnXX389F1xwAR0dHUSjUXbs2MHLL7/Mpk2bmDlzJmeccQbPPPMMZ555ZlKfjo4OrrjiCtauXcvixYu57LLLuP322/n4xz/OAw88QGVlJSLS01/h5ptv5tFHH2XWrFlJ+zBs376dKVOmMHbs2J7HWNevX8/GjRspLCzk5JNP5n3vex8nnXTSgNeyq6uLz372szz00EMcccQR3HvvvXz1q1/lzjvvBGDlypU888wzfOhDHxowr/6wkoOVHIaM746++8HIcIxGuzOW99q1aykpKeHkk09mxYoVrF27lldffRUIehRffPHFAFx66aU8/fTT7Nu3j5aWFs466ywALr/8cp588kl27dpFfX09F1xwARA0/saqcU455RRmz55NTk4OK1asoKampk+fLVu2sGDBAhYvXnxY/pMnT6agoIArr7ySP/7xjz15n3HGGVxxxRX87Gc/6ynxxNPQ0MARRwSDn8ZKDueccw5Tp05l3Lhx/OM//iNPP/10Stdqy5YtbNy4kXPOOYcVK1Zwyy23HPa02/Tp09m5c+gP2Yz6kkP+i88R8bjNwadflH3hu6PvfuCXY3+/8DOFqnL55ZfzzW9+c8C0/T2WOX78+D7fi+94lpubSyQSSU+SoI/C+vXrWbt2Lffffz+33norjz/+OHfccQcvvPACf/7zn1m1ahUlJSVMnTq1Z79x48b19DOIOSaeR+J6Xl4e0bhajdj+qsrSpUt57rnnkjp2dHQwbty4tM8tkVFdcigvLyc3R+j2uORQXl6ebYUB8d3Rdz8YGY6ZHDDu7LPP5v7776exsRGAvXv38tprwWjS0Wi05wmi//3f/+XMM89k8uTJTJkyhaeeegqAe+65h7POOovc3Fxmz57Ngw8+CAS9kQfjfcwxx1BTU8O2bdsOy7+trY19+/bx3ve+l+9///uUlZUBwTDcp556KjfffDNHHHEEO3bsOCy/xYsX95RUYj6PPfYYe/fupb29nQcffJAzzjjjsH3mzZtHRUUFnZ2dtLS0sHbt2h63119/vSc4dHV1Hfa029atWzn++OPTPudERnXJYfHixeSt30BnJHPF5aESK9b6jO+OvvvByHDM5PP5xx13HLfccgvvfve7iUaj5Ofnc9tttzFv3jzGjx/P+vXrueWWW5g+fTr33nsvAHfffTdXX301Bw8e5KijjuKuu+6ioKCAe+65h09/+tPccMMN5Ofnc99996XtU1BQwF133cVFF11EJBLh5JNP5uqrr2bv3r2cf/75dHR0oKp873vfA+DLX/4yVVVVqCpnn312r6fPxo8fz9FHH822bds46qijgKCa60Mf+hB1dXVceumlvdob5syZw4c//GGOP/54FixYwIknngjAmDFjuP/++/nc5z7Hvn37iEQifOELX2Dp0qV0dXWxbdu2lNouBkIGarEfKZx00kma7mQ/VVVVfOPpZpoPHOKha5I3TGWbqqoqFi1alG2NfvHd0Xc/yL7j5s2bOfbYY/tN09HRkZUOXBMmTKCtrS2ltNlyTIUHHniAkpISvva1r2XM8YEHHqC0tJSvf/3rvd5L9hmLSImqJo0ko7rkMGPGDPJyWujyuM1hxowZ2VYYEN8dffeDkeGY7ZFjU8FnxwsuuIA9e/Zk1DESiXDttdc6yWtUtzm0tLR43+bg+/DD4L+j734wMhwH04DrglRLDZA9x1T55Cc/mVHHiy66iKKiIid5jergUFBQQF5uDhGP+zn4WkSOx3dH3/3AD8eBqphHwiQ15picwTQfDLuliNwpIo0isrGP90VE/kdEtonIKyKyMpM+eZ6XHAxjOCgoKGDPnj2D+hIx/CY2n0O6P0Cy0ebwS+BW4Fd9vP8eYFH4OhW4PfzrnI6ODu87waU7Bns28N3Rdz/IvuPs2bOpq6vrGZoiGZFIxPv5EswxObGZ4NJh2K+iqj4pIvP7SXI+8CsNfsI8LyJFIvIWVW1w7VJUVEReTrPXneBc1R9mEt8dffeD7Dvm5+cPOEtYa2srkyZNGiajwWGO7vCxgm4WEN+DpC7c5pzdu3eTm5Pjdclh9+7d2VYYEN8dffcDc3SFObrDx+CQMiJylYi8JCIvNTQ00NTURENDA/X19TQ3N1NdXU17ezsVFRVEo1FKS0uBN8axaWlpIS8HDnV10d7eTnV1Nc3NzdTX1xPLr6amhra2NiorK4lEIj09ImN5xP6Wl5fT2dlJVVUVra2t1NbW0tjYSGNjI7W1tbS2tlJVVUVnZ2dPb9jEPMrKyohEIlRWVtLW1kZNTQ0TJkxI65xKS0uJRqNUVFQM2zkdeeSRaZ1Tup/TUM9p7ty5Gf+chnpO0WjUu3sv8Zyi0ah3917iOcV/1j7ce8nOKRKJeHPv9UdWOsGF1UoPq2qvPt4i8hNgnar+NlzfArx9oGqlwXSCKy8v5481OdxfUkf5jeemte9wUV5ezrJly7Kt0S++O/ruB+boCnNMj/46wflYclgDXBY+tXQasC8T7Q0Ay5Yt8/5pJV9uov7w3dF3PzBHV5ijO7LxKOtvgeeAY0SkTkSuFJGrReTqMMkjwKvANuBnwGcy5RIM2Z3jdYP0SBjK2XdH3/3AHF1hju4Y1WMrAXz30S38eN02Xv3m+zJgZRiG4S8jrVpp2CgpKSEvV4gqRD2tWhoJvzJ8d/TdD8zRFebojlFfcrj18Sq++7etVH3jPeTnjupYaRjGKMNKDn1QVlZGbjjOia+N0rHH4nzGd0ff/cAcXWGO7hjVwWHp0qXk5QRT8/naEW7p0uGfsjFdfHf03Q/M0RXm6I5RHRy2bdtGbiw4dPs5MmtsmkKf8d3Rdz8wR1eYoztGdXCYPXs2+bl+lxzSHSwrG/ju6LsfmKMrzNEdozo4NDU1ed/m0NTUlG2FAfHd0Xc/MEdXmKM7RnVwmDBhgvdtDhMmTMi2woD47ui7H5ijK8zRHaM6OHR1dfW0OXR72ku6q6sr2woD4ruj735gjq4wR3eM6uAQjUbJC9scujydKjTqqVc8vjv67gfm6ApzdMeoDg6FhYVvlBw8rVYqLCzMtsKA+O7oux+YoyvM0R2jOjjs3buXvLBB2tfB9/bu3ZtthQHx3dF3PzBHV5ijO0Z1cJg5c2ZPg7SvJYeZM2dmW2FAfHf03Q/M0RXm6I5RHRy2b99Obk8/Bz/rAbdv355thQHx3dF3PzBHV5ijO0Z1cFiyZIn3j7IuWbIk2woD4ruj735gjq4wR3eM6uCwYcOGuOEz/AwOGzZsyLbCgPju6LsfmKMrzNEdo37I7hdr9nLRHc/x6ytP5cxF0zJgZhiG4SdDHrJbRIpTeBU5tR4GgmlC/W5zGAkTg/ju6LsfmKMrzNEdKZUcRKQD2AlIP8lyVXWuK7F0GWzJ4ZW6Fs679Rl+cflJnH3sjAyYGYZh+ImLyX42q+pRqrqgrxewx53y8FBaWtpTcujytM2htLQ02woD4ruj735gjq4wR3ekWnIoUNWOoabJJIMpOUSjUaoaD3DuD57kto+t5H0nvCVDdoMnGo2Sk+P3cwO+O/ruB+boCnNMjyGXHOK/9EXkrQOlGSlUVlb2jK3ka5tDZWVlthUGxHdH3/3AHF1hju4YTPi6yLlFlliwYIH3PaQXLFiQbYUB8d3Rdz8wR1eYozsGDA4iskZEfigil4vI8UDeMHgNCzt37ox7WsnP4LBz585sKwyI746++4E5usIc3THgF72qnici84CVwEeAeRm3GiaKi4vp9HzgveLi4mwrDIjvjr77gTm6whzdkWqbw2uq+oCqfg34doadho2DBw/GDdntZ5vDwYMHs60wIL47+u4H5ugKc3THYNocLnRukSVycnLIz/W7WsmXpxr6w3dH3/3AHF1hju4YsFpJRNYA24FSoCSVfUYK+fn53k/2k5+fn22FAfHd0Xc/MEdXmKM7Bgxhqnoe8D2gFUdtDiKyWkS2iMg2Ebk+yftzReTvIvKyiLwiIu8d6jGT0dbW9sZkP54Gh7a2tmwrDIjvjr77gTm6whzdkUrJ4fcEw2bUEJQe7hnKAUUkF7gNOAeoA14UkTWqWhGX7GvA71X1dhE5DngEmD+U4yZj2rRp3pccpk3zfzBA3x199wNzdIU5uiOVksOHVfUi4A7gTODFIR7zFGCbqr6qqoeA3wHnJx4WmBQuTyYY18k5dXV1Pf0curr9bJCuq6vLtsKA+O7oux+YoyvM0R2p9HN4l4h8H/hX4DlgzhCPOQvYEbdeF26L50bgUhGpIyg1fLYPt6tE5CUReamhoYGmpiYaGhqor6+nubmZ6upq2tvbqaioIBqN9oxpEhsV8cCBA4CSI9DR2UV1dTXNzc3U19cTy6+mpoa2tjYqKyuJRCKUlZUdlkfsb3l5OZ2dnVRVVdHa2kptbS2NjY00NjZSW1tLa2srVVVVdHZ2Ul5enjSPsrIyIpEIlZWVtLW1UVNTw5QpU9I6p9LSUqLRKBUVFbS3tw/LOc2ZMyetc0r3cxrqOS1cuDDjn9NQzyk3N9e7ey/xnHJzc7279xLPKf6z9uHeS3ZOIuLNvdcvqtrvC6gFfgJ8DFg8UPoU8rsQ+Hnc+seBWxPSfAm4Nlw+HagAcvrLd9WqVZouGzZsUFXVRf/+iH7rL5vT3n84iDn6jO+OvvupmqMrzDE9gJe0j+/UVDrBzRWR2cAqgl/zi1T1owPt1w/1HF76mB1ui+dKYHV4/OdEpACYBjQO4bi9WL58OQC5OeJtm0PM0Wd8d/TdD8zRFebojlQ7wdWp6kOqekN8YBCRwUyG+iKwSEQWiMgYgieg1iSkqQXODo9xLFAAvD6IY/VLrJiVlyPe9pAeCROD+O7oux+YoyvM0R0p98YQkS+LyHPhl3WMehG5Op0DqmoEuAZ4FNhM8FTSJhG5WUTOC5NdC3xKRMqA3wJXhEUgp6xatQqA3FzxdlTWmKPP+O7oux+YoyvM0R3pdNVbCHyBuF/wqrof+EC6B1XVR1R1saoerarfCLfdoKprwuUKVT1DVZer6gpV/Vu6x0iFw0oOnlYrjYRfGb47+u4H5ugKc3RHSpP9AIjIxQTtAz9T1dZw2zSCx1KLMmaYIoOdJhTgtP9cy1mLj+DbF57g2MowDMNfXEwTiqreG6avFpEXReQbwD8AW9xoDj+xx8VyPS45xBx9xndH3/3AHF1hju5IawQoVf0OMBf4f0AucB2wPwNew8LixYsByMsVb0dljTn6jO+OvvuBObrCHN2R9vCAqtoethlcr6pvA27JgNewUFtbCwQlhy5PSw4xR5/x3dF3PzBHV5ijO4Y8dqyqrnPgkRVmzJgBBA3S3Z4+yhpz9BnfHX33A3N0hTm6Y2QMLJ4hWlpaAMjLyfG2zSHm6DO+O/ruB+boCnN0x6gODgUFBYDfbQ4xR5/x3dF3PzBHV5ijO9LpBCciMtRB97zE56eVDMMwskE6j7IqwQipbxo6OjoAv4fPiDn6jO+OvvuBObrCHN2RbrVSqYicnBGTLFBUVAT4PfBezNFnfHf03Q/M0RXm6I50g8OpwHMiUh1O31kuIq9kQmw42L17NwD5uTnejq0Uc/QZ3x199wNzdIU5umPAIbsTODcjFlli7ty5gN8lh5ijz/ju6LsfmKMrzNEd6faQfg0oIhhs7wNAUbhtRLJ161bA74H3Yo4+47uj735gjq4wR3ekFRxE5PPAb4Dp4evXIpJ0Cs+RwLJly4DwaSVPG6Rjjj7ju6PvfmCOrjBHd6Tb5nAlcGo4vPYNwGnAp9xrDQ9vDNntb5vDSBje13dH3/3AHF1hju5IechuABEpB05W1Y5wvQB4UVWzHgqHMmT353/3MmU7Wlj35Xc4tjIMw/AXJ0N2h9wFvCAiN4rIjcDzwC+G6Jc1YhHc505wI+FXhu+OvvuBObrCHN2RzmQ/QjDZzxHAmeHmp1T15Qy5pcVQSg7/en8ZT1U18dxXznZsZRiG4S+uJvtR4BFVLVXV/wlfXgSGwVJWVgZAbk4OXZ42SMccfcZ3R9/9wBxdYY7uGNU9pJcuXQqEQ3Z72iAdc/QZ3x199wNzdIU5umNU95Detm0b4HebQ8zRZ3x39N0PzNEV5uiOlHtIh20OVwEjttNbIrNnzwYgP9ffHtIxR5/x3dF3PzBHV5ijO9Jtc7hNVV9LfGXQL6M0NTUBQZuDryWHmKPP+O7oux+YoyvM0R2jus1hwoQJQKzNwc/gEHP0Gd8dffcDc3SFOboj3YH3TgUuFZEa4AAgBIWKE1yLDQddXV3AGwPvqSpB7Zk/xBx9xndH3/3AHF1hju4Y1aOyRsMnlPJygoAQiSr5uX4Fh6inT1HF47uj735gjq4wR3ekVK0kIv8KPaOynpLQ3vDpTApmksLCQgDycoPL4GPVUszRZ3x39N0PzNEV5uiOVNscPhK3/JWE91anc0ARWS0iW0Rkm4hc30eaD4tIhYhsEpH/TSf/dNi7dy9weMnBN2KOPuO7o+9+YI6uMEd3pFqtJH0sJ1vvOxORXOA24BygDnhRRNaoakVcmkUEAegMVW0Wkemp5p8uM2fOBII2B4BuD3tJxxx9xndH3/3AHF1hju5IteSgfSwnW++PU4Btqvqqqh4Cfgecn5DmUwSPzDYDqGpjGvmnxfbt2wHIC9sZujysC4w5+ozvjr77gTm6whzdkWrJYbmItBKUEsaFy4TrBWkcbxawI269juAJqHgWA4jIM0AucKOq/jWNY6TMkiVLgLiSg4fVSjFHn/Hd0Xc/MEdXmKM7Uio5qGquqk5S1Ymqmhcux9bzHTvlAYuAtwMfBX4mIkXJEorIVSLykoi81NDQQFNTEw0NDdTX19Pc3Ex1dTXt7e1UVFQQjUYpLS0F3hgyd+3atUSjUV7ftQuA6u01NDc3U19fTyy/mpoa2traqKysJBKJ9AyaFcsj9re8vJzOzk6qqqpobW2ltraWxsZGGhsbqa2tpbW1laqqKjo7OykvL0+aR1lZGZFIhMrKStra2qipqeH5559P65xKS0uJRqNUVFTQ3t5OdXV1xs+ppKQkrXNK93Ma6jlt2LAh45/TUM/pqaee8u7eSzynp556yrt7L/Gc4j9rH+69ZOf05JNPenPv9Udak/0MFRE5naAkcG64/hUAVf1mXJo7gBdU9a5wfS1wvaq+2F/eQxmy+w8ldVx7XxlPfvkdzJ06Mp4kMAzDGCouJ/sZKi8Ci0RkgYiMIXgKak1CmgcJSg2IyDSCaqZXMyHTM01obuxpJf/aHEbCxCC+O/ruB+boCnN0x7AGB1WNANcAjwKbgd+r6iYRuVlEzguTPQrsEZEK4O/Al1V1TyZ8Vq1aBbzR5uDjo6wxR5/x3dF3PzBHV5ijO4a75ICqPqKqi1X1aFX9RrjtBlVdEy6rqn5JVY9T1WWq+rtMucTq4nr6OXj4KGvM0Wd8d/TdD8zRFebojrSGzxCRscCHgPnx+6rqzW61hocVK1YAkJfjbw/pmKPP+O7oux+YoyvM0R3plhweIuiXECEYeC/2GpFUVlYCkOtxm0PM0Wd8d/TdD8zRFebojnQH3putqmkNl+EzCxYsAN6oVvKx5BBz9BnfHX33A3N0hTm6I92Sw7MisiwjJllg586dwBsN0l0etjnEHH3Gd0ff/cAcXWGO7ki35HAmcIWIbAc6GeHzORQXFwN+tznEHH3Gd0ff/cAcXWGO7ki35PAegt7L7wY+ALw//DsiOXjwIBD/KKt/bQ4xR5/x3dF3PzBHV5ijO9IKDuH8DUUEAeEDQNFInkM6JywxxCb48bHkEHP0Gd8dffcDc3SFObojLUsR+TzwG2B6+Pq1iHw2E2LDQX5+MCyUz53gYo4+47uj735gjq4wR3ekG8KuBE4NO63dAJxGMMT2iKStrQ14o83Bx05wMUef8d3Rdz8wR1eYozvSDQ4CdMetd5PGZD++MW3aNMDvNoeYo8/47ui7H5ijK8zRHekGh7uAF0TkRhG5EXge+IVzq2Girq4O8LufQ8zRZ3x39N0PzNEV5uiOtB5lVdXvicgTwBnhpn9S1Zfdaw0PCxcuBOJHZfUvOMQcfcZ3R9/9wBxdYY7uSLvZXFVLVPV/wteIDQwAmzZtAvzu5xBz9BnfHX33A3N0hTm6I6XJfkTkaVU9U0T2c/ic0bFOcJMyJZgqQ5ns5/X9nZz8jf/j6x88no+fNs+xmWEYhp8MebIfVT0z/DsxborQ2DShWQ8Mg6Vnsp+eIbv9a5AeCROD+O7oux+YoyvM0R3p9nP4dirbRgo9k/143AluJEwM4ruj735gjq4wR3ek2+ZwTpJt73Ehkg1iETw/1s/Bw+AwEn5l+O7oux+YoyvM0R2ptjn8M/AZ4CigOu6ticCzqnpJZvRSZyhtDociURZ/7S98+dxj+Jd3jIwnCQzDMIbKkNscgP8lGEtpDW+Mq/QBYJUPgWGwlJeXA35PExpz9BnfHX33A3N0hTm6I6V+Dqq6D9gHfFREphCMzFoAICKo6pOZU8wcixcvBiAnRxDxs4d0zNFnfHf03Q/M0RXm6I50G6Q/CTwJPArcFP690b3W8FBbW9uznJcjXrY5xDv6iu+OvvuBObrCHN2RboP054GTgddU9R3AiUCLa6nhYsaMGT3LeTk5Xj6tFO/oK747+u4H5ugKc3RHusGhQ1U7AERkrKpWAse41xoeWlpaepbzcsTLNod4R1/x3dF3PzBHV5ijO9KdJrRORIqAB4HHRKQZGLGT/RQUFPQs5+YK3R62OcQ7+orvjr77gTm6whzdke7AexeEizeKyN+BycBfnFtlgbwcocvDaiXDMIxskG6D9N1hyQFVfQJ4CvhJBryGhY6Ojp7l3Byh28NqpXhHX/Hd0Xc/MEdXmKM70m1zOEFVW2IrqtpM0Cg9IikqKupZzsvJ8fJppXhHX/Hd0Xc/MEdXmKM70g0OOWE/BwBEpJj02y28Yffu3T3LeZ62OcQ7+orvjr77gTm6whzdkW5w+G/gORH5uoh8HXgW+K90Dyoiq0Vki4hsE5Hr+0n3IRFREUnavXuozJ07t2c519N+DvGOvuK7o+9+YI6uMEd3pBUcVPVXwIeA3eHrH1X1nnTyEJFc4DaCAfuOI+h1fVySdBMJ+lW8kE7+6bB169aeZV8fZY139BXfHX33A3N0hTm6I+0qIVXdBAxlKqNTgG2q+iqAiPwOOB+oSEj3deDbwJeHcKx+WbZsWc9ybk6Ol8NnxDv6iu+OvvuBObrCHN2RUslBRJ4O/+4Xkda4134RaU3zmLOAHXHrdeG2+OOtBOao6p8H8LpKRF4SkZcaGhpoamqioaGB+vp6mpubqa6upr29nYqKCqLRKKWlpcAbQ+Y+9thjRKNRKioqmDAmh11799Pc3Ex9fT2x/Gpqamhra6OyspJIJEJZWdlhecT+lpeX09nZSVVVFa2trdTW1tLY2EhjYyO1tbW0trZSVVVFZ2dnz8BbiXmUlZURiUSorKykra2Nmpoann322bTOqbS0tOec2tvbqa6uzvg5rV+/Pq1zSvdzGuo5xV6Z/JyGek7r1q3z7t5LPKd169Z5d+8lnlP8Z+3DvZfsnNatW+fNvdcfKQ3Z7RIRuRBYraqfDNc/DpyqqteE6znA48AVqlojIuuA61S13/G4hzJkN8CXfr+B56r38NxXzh50HoZhGCOJIQ/ZLSL3hH8/78CnHpgTtz473BZjInA8sE5EaoDTgDWZaJSOn3RjdtE4drd20OXZVKEjYWIQ3x199wNzdIU5uiPVyX4qgHcR9IZ+OyDx76vq3pQPKJIHbAXOJggKLwIfC9sykqVfxzCUHO59sZZ/+0M5T/3rO5hTXDjofAzDMEYKLib7uQNYCywBSoGSuFda38iqGgGuIRjuezPwe1XdJCI3i8h56eQ1VGJ1gwCzioKAUNfcPpwKAxLv6Cu+O/ruB+boCnN0R1ptDiLyY1X9TAZ9Bs1gSg6RSIS8vOCBre1NB3jHd9fx3YuWc+Gq2ZlQHBTxjr7iu6PvfmCOrjDH9HDR5vB0uHiZg6eVvGHbtm09y2+ZHIyUWO9ZySHe0Vd8d/TdD8zRFebojlSnCT0z/DshszrDy+zZb5QQCvJzmTZhLPUtB7No1Jt4R1/x3dF3PzBHV5ijO9IdlfWisOcyIvI1EfmjiIzYgfeampoOW581ZRw7W/waMTHR0Ud8d/TdD8zRFebojnTHVvoPVd0vImcSPL30C4LG6hHJhAmHF4RmF42jvsWvaqVERx/x3dF3PzBHV5ijO9INDt3h3/cBPw17MI9xqzR8dHV1HbY+a0oQHKIeDcCX6Ogjvjv67gfm6ApzdEe6waFeRH4CXAw8IiJjB5GHN0QTxlKaVTSOQ5EoTQc6s2TUm0RHH/Hd0Xc/MEdXmKM70v1i/zBB/4Rzw0l/isngwHiZprDw8M5us4rGAX49sZTo6CO+O/ruB+boCnN0R7pDdh9U1T+qalW43qCqf8uMWubZu/fwjt2zpoTBwaN2h0RHH/Hd0Xc/MEdXmKM7XDyttDIzapln5syZh633BAePSg6Jjj7iu6PvfmCOrjBHd7h4Wul291rDw/bt2w9bn1SQz8SCPK9KDomOPuK7o+9+YI6uMEd3jOqnlZYsWdJr26yicV6VHJI5+obvjr77gTm6whzdMaqfVtqwYUOvbXOKC6nd608v6WSOvuG7o+9+YI6uMEd3pDvwXiGwGihX1SoReQuwzIdG6aEO2R3jlocruOf519h882pycmTgHQzDMEYoLobsBoKnlYC/A1NE5G3AIsCv8SbSINmkG/OmFtIZidK434++DiNhYhDfHX33A3N0hTm6I92SwyeBzxPM3raBYJa251T1nRmxSwNXJYcnt77OZXeu596rTuPUo6Y6MDMMw/ATZyUHgsBwMvCaqr4DOBFoGZpe9ohNvB3PvKlBB5XX9vjR7pDM0Td8d/TdD8zRFebojnSDQ4eqdgCIyFhVrQSOca81PKxYsaLXtplF48jNEV7be2D4hZKQzNE3fHf03Q/M0RXm6I50g0OdiBQBDwKPichDwGuupYaLysrKXtvyc3OYVTTOm5JDMkff8N3Rdz8wR1eYozvSmqtOVS8IF28Ukb8Dk4G/OrcaJhYsWJB0+7yp/jzO2pejT/ju6LsfmKMrzNEdg+6joKpPqOoaVT3kUmg42blzZ9Lt86YWUtPkR7VSX44+4buj735gjq4wR3ekVHIQkf1AsseaBFBVneTUapgoLi5Oun1e8XhaOyK0HDxEUWF2O4D35egTvjv67gfm6ApzdEdKJQdVnaiqk5K8Jo7UwABw8GDyqqO5Hj2x1JejT/ju6LsfmKMrzNEdKQUHEVkoImck2X6GiBztXmt4yMlJfvo9j7N60O7Ql6NP+O7oux+YoyvM0R2pWv4AaE2yvTV8b0SSn5+fdPvc4jA4eNDu0JejT/ju6LsfmKMrzNEdqQaHGapanrgx3DbfqdEw0tbWlnR74Zg8pk8c60XJoS9Hn/Dd0Xc/MEdXmKM7Ug0ORf28N86BR1aYNm1an+/Nm1rIdg9KDv05+oLvjr77gTm6whzdkWpweElEPpW4MRxraWSMIpWEurq6Pt9bNquIjfX76Ix095lmOOjP0Rd8d/TdD8zRFebojlSDwxeAfxKRdSLy3+HrCeBKgvGWUkZEVovIFhHZJiLXJ3n/SyJSISKviMhaEZmXTv7psHDhwj7fO/WoYjojUcrr9mXq8CnRn6Mv+O7oux+YoyvM0R2pPsq6W1X/AbgJqAlfN6nq6aq6K9WDiUgucBvwHuA44KMiclxCspeBk1T1BOB+4L9SzT9dNm3a1Od7J88PnkV+YXt2JwPvz9EXfHf03Q/M0RXm6I6UhuwWkVJVXekgzenAjap6brj+FQBV/WYf6U8EblXVXo/RJuJqyO543v39J3jL5HHc/YlTnOZrGIbhAy6G7D42rObp61UOpNLKMgvYEbdeF27riyuBv/T1pohcJSIvichLDQ0NNDU10dDQQH19Pc3NzVRXV9Pe3k5FRQXRaLRnqNzYZBuPPfYY0WiUiooK2tvbqa6uprm5mfr6ehoaGjjhyELWb99DS+t+KisriUQilJWVHZZH7G95eTmdnZ1UVVXR2tpKbW0tjY2NNDY2UltbS2trK1VVVXR2dlJeXp40j7KyMiKRCJWVlbS1tVFTU8Ozzz6b1jmVlpb2e05NTU3U1NTQ1tbm7JzWr1+f1jml+zkN9Zxir0x+TkM9p3Xr1mX8cxrqOa1bt867ey/xnOI/ax/uvWTntG7dOm/uvf5IteSQSr1/t6r229IiIhcCq1X1k+H6x4FTVfWaJGkvBa4BzlLVAadly0TJYU3ZTj7325dZc80ZnDC7yGnehmEY2WbIJQdVfS2FVypN8PXAnLj12eG2ROF3AV8FzkslMAyWgabrOyVsd1ifxXaHkTCloO+OvvuBObrCHN2R1jShQz6YSB6wFTibICi8CHxMVTfFpTmRoCF6tapWpZp3JkoOAGd95+8smj6Rn1+eNLgahmGMWFxOEzokVDVCUFX0KLAZ+L2qbhKRm0XkvDDZd4AJwH0iskFE1mTKJ1av1x9nLJzGs9VNHDwUyZRGv6TimG18d/TdD8zRFebojmEtOWSSwZQcOjs7GTt2bL9pXnh1Dxf/9Hl++JEVnL+iv7bzzJCKY7bx3dF3PzBHV5hjenhTcvCN2traAdOcPL+YmZMLeODlXk0jw0IqjtnGd0ff/cAcXWGO7hjVwWHGjBkDpsnJEc4/cRZPVTXR1JaxtvE+ScUx2/ju6LsfmKMrzNEdozo4tLS0pJTughNn0R1VHi4b/un9UnXMJr47+u4H5ugKc3THqA4OBQUFKaVbPGMix75lEg9sGP7gkKpjNvHd0Xc/MEdXmKM7RnVwSIcLTpxJ2Y4WL4bxNgzDyDSjOjh0dHSknPa85bMQgQeHuWE6Hcds4buj735gjq4wR3eM6uBQVFSUctojJxdw+lFTeWhDPcP5+G86jtnCd0ff/cAcXWGO7hjVwWH37t1ppf/gibOo2XOQDTtaMiOUhHQds4Hvjr77gTm6whzdMaqDw9y5c9NKv/r4IxmTlzOsVUvpOmYD3x199wNzdIU5umNUB4etW7emlX5SQT7nHDuDh19poKs7miGrw0nXMRv47ui7H5ijK8zRHaN6+IzB8LdNu7jqnhLuuuJk3rFkesaPZxiGkSls+Iw+GMzQuW8/ZjpFhfk8uGF4qpZGwvC+vjv67gfm6ApzdIeVHAbBVx8o5w+ldbz0tXOYMDZvWI5pGIbhGis59MFgI/gHT5xFR1eUv23a5dioNyPhV4bvjr77gTm6whzdYSWHQRCNKm/7zt9ZMG0891x56rAc0zAMwzVWcuiD2ETg6ZKTI1y4ajZPVTXx5NbXHVsdzmAdhxPfHX33A3N0hTm6Y1SXHCKRCHl5g2sz6Ojq5v0/epr9HV08+oW3UVQ4ZlD5DMRQHIcL3x199wNzdIU5poeVHPpg27Ztg963ID+XH1y8gj1th/j3B8ozNqTGUByHC98dffcDc3SFObpjVAeH2bNnD2n/42dN5tp3H8Mj5bu444lXD3tPVdl74NCQ8oehOw4Hvjv67gfm6ApzdMeoDg5NTU1DzuPqs47iA8tn8u2/VvLXjQ092+99cQenfOP/KK/bN6T8XThmGt8dffcDc3SFObpjVAeHCRMmDDkPEeE7F57AijlFfPHeMuqaD9IdVW5/oppIVLn54U1DqnJy4ZhpfHf03Q/M0RXm6I5RHRy6urqc5FOQn8ttl6wE4JaHN/Popl28tucg7zp2Oi/WNPNI+eD7Q7hyzCS+O/ruB+boCnN0x6gODtGou8HzZhWN45p3LuSvm3Zx45pNzJ9ayI8vWcWSIyfyn49spqOru9/997R1cu3vy9i6e3/GHDOF746++4E5usIc3TGqg0NhYaHT/D751gUsmDaexv2dXPnWoxiTl8ON5y2lvqWdbz6yuc/9Orq6ueqeEv5QWsd/PLjxsGoo146ZwHdH3/3AHF1hju4Y1cFh7969TvMbm5fLf114AucuncGFK4MnEk47aiqfOGMBdz/3Gn/f0thrn46ubq69r4yS15p593EzeGH7Xp6seqPBKl1HVeXBl+uHZWiPGK6vo2t89wNzdIU5umNUd4Jrb29n3LhxGTJ6g46ubj542zM07u/k7CXTmTZxLFPHjyESVe56Zju7Wzv5ynuW8E9nLOCd/72OyePy+dM1Z5KTI2k57mnr5Po/lvNYxW7G5uXw2BfPYu7U3r9SXqlr4YVX93LJaXMpHDP0zjjDdR0Hi+9+YI6uMMf0sE5wfbB9+/ZhOU5Bfi4/+uiJLJg2nqeqmvj5U69yy583862/VDK3uJDffuo0Pn3W0YzJy+Hady9m085W7nq2Ji3HJ7a+zuofPsUTW17nC+9aRG6OcPPDm3qle23PAS67cz3feGQz53zvSR6rGPqUhcN1HQeL735gjq4wR3eM6pJDNBolJ2f446Oq0toeoe1QhJmTCxCRnve6o8qn73mJ/9vcyNfedyyLpo/nT6/sonbPQfYc6GTBtPGcfewM3rlkOjMmFdDY2sEP11bxmxdqWTxjAj+4+ESOmzmJnz5ZzX8+UslPPr6Kc5ceCcD+ji7+8cfP8npbJzedt5Tb11VTuWs/3/7QMi4+efBTF2brOqaK735gjq4wx/Tor+SQleAgIquBHwK5wM9V9VsJ748FfgWsAvYAF6tqTX95DiY4lJaWsnLlyrT2GQ4ORaJ87rcv89ew3WBSQR7HvmUSRYX5bKxvpb6lHYDj3jKJV5va6OpWLjt9Hv+2egkF+bkAdHVHee8Pn6KqsY2F0ycwpTCf8vp9dHUr93ziFP5h4TQ6I91c9asSnqx6nW9esIwPnzSHnBzp06svfL2OMXz3A3N0hTmmh1fBQURyga3AOUAd8CLwUVWtiEvzGeAEVb1aRD4CXKCqF/eX73AO2T0cRLqj/Pzp7cyZUsjZx07v+dJXVbbs3s/azY08sfV15kwp5LPvXMj8aeN75dG4v4OHXt7JU9ua2N/RxYo5RaxeeiSnHjW1J01HVzdX3v0iz2zbw5GTCjjtqGJa2rtoPnCInBwhPyeHvFyhcEweZy2extnHzqAgP5eu7ij5uTmMzQteebl+/BIyDCN1fAsOpwM3quq54fpXAFT1m3FpHg3TPCciecAu4AjtR3YwwaGkpIRVq1YN4iyGj+Fw7Ix080h5A39+ZRcb6/cxbeIYisePRVWJdCuRaJTX93dSs+dgn3nk5khPoBibl8uYvBxy0yyFpF9mSW2njo4OCgoKBnWM+Cq/TNLR3k6BJ42UfWGObsiE418+/1byB/EDrb/gkI1xY2cBO+LW64DEGXN60qhqRET2AVOBwwYlEZGrgKsAZs6cSVNTE11dXUSjUQoLC9m7dy8zZ85k+/btLFmyhA0bNrBy5cqeL1wRIRqNUllZyYIFC9i5cyfFxcUcPHiQnJwc8vPzaWtrY9q0adTV1bFw4UI2bdrE8uXLe/KI/S0vL2fx4sXU1tYyY8YMWlpaer6QOjo6KCoqYvfu3cydO5etW7eybNmyXnmUlZWxdOlStm3bxuzZs2lqamLevHk0NDSkfE6lpaWsWLEirXOq3LSJC05cztzoblZdfnaf5/Tyq7t4ZVdn8A0bjTBm7Dj2tOxj3IRJNOxuYnLxVHbs3M3kKVNpaHydoinFtLQ0M3nyZPbvb6OwsJDOzk7y8vLCjkBKbm4ehw4domBcAQfaDjBx0iRampuZUlzM3r17KS4upnnvXoqmTGF/ayvjJ4ynvb2dMWPGEolEEBFEhEgkwtixY2k/2M6EiRPYt28fRUVFNDc3M+Ut02lubqZoyhT2texj4sSJHDx4gIKCAg4d6iI3/Kfq7o4yZkw+HR0dFBaOp3X/foomT2JvczPFU6b0/G1paWHS5Em0tbVROC7unDQKCrm5uRw6dIhx48bRduAAkyZOpKWlhSlxeTQ3N1NUVETr/v1MGD+e9nZhzJgxdHd3g0CO5PSc08H2g0yYMIHWfa0UFRX19tm3j4kTJ3Dw4EEKxhbQ1dVFTnhO0e4o+fn5dHR2UFhYyP79bRRNnjy4cxovaZ5T+/Cf04zpGf6cXJwTzj+nXbt2kYOm/R3RL6o6rC/gQoJ2htj6x4FbE9JsBGbHrVcD0/rLd9WqVZouJSUlae8z3Jjj0PHdT9UcXWGO6QG8pH18p47qaiWfnhroC3McOr77gTm6whzTw7d+Di8Ci0RkgYiMAT4CrElIswa4PFy+EHi8v8AwWAYsVnmAOQ4d3/3AHF1hju4Y9jYHDdoQrgEeJXiU9U5V3SQiNxMUcdYAvwDuEZFtwF6CAOKcBQsWZCJbp5jj0PHdD8zRFebojqyUbVT1EVVdrKpHq+o3wm03hIEBVe1Q1YtUdaGqnqKqr/af4+DYuXNnJrJ1ijkOHd/9wBxdYY7u8KPiK0sUFxdnW2FAzHHo+O4H5ugKc3THqA4OBw/2/dy+L5jj0PHdD8zRFebojlEdHHx5YqA/zHHo+O4H5ugKc3THyLDMEPn5+dlWGBBzHDq++4E5usIc3fGmGZVVRF4HXktzt2kk9Lr2EHMcOr77gTm6whzTY56qHpHsjTdNcBgMIvJSXx1AfMEch47vfmCOrjBHd4zqaiXDMAwjORYcDMMwjF6M9uDw02wLpIA5Dh3f/cAcXWGOjhjVbQ6GYRhGckZ7ycEwDMNIwqgMDiKyWkS2iMg2Ebk+2z4AIjJHRP4uIhUisklEPh9uLxaRx0SkKvw7xQPXXBF5WUQeDtcXiMgL4fW8NxxtN5t+RSJyv4hUishmETndt+soIl8MP+eNIvJbESnI9nUUkTtFpFFENsZtS3rdJOB/QtdXRGRYJkXuw/E74Wf9iog8ICJFce99JXTcIiLnZssx7r1rRURFZFq4npXrmAqjLjiEc1jfBrwHOA74qIgcl10rACLAtap6HHAa8C+h1/XAWlVdBKwN17PN54HNcevfBr6vqguBZuDKrFi9wQ+Bv6rqEmA5gas311FEZgGfA05S1eMJRif+CNm/jr8EVids6+u6vQdYFL6uAm7PouNjwPGqegLB/PRfAQj/fz4CLA33+XH4/58NR0RkDvBuoDZuc7au44CMuuAAnAJsU9VXVfUQ8Dvg/Cw7oaoNqloaLu8n+EKbReB2d5jsbuCDWREMEZHZwPuAn4frArwTuD9MklVHEZkMvI1g2HdU9ZCqtuDZdSQYLn9cOJlVIdBAlq+jqj5JMER+PH1dt/OBX4UTij0PFInIW7LhqKp/U9VIuPo8MDvO8Xeq2qmq24FtBP//w+4Y8n3gX4H4ht6sXMdUGI3BIdkc1rOy5JIUEZkPnAi8AMxQ1YbwrV3AjGx5hfyA4AaPhutTgZa4f85sX88FwOvAXWHV189FZDweXUdVrQe+S/ALsgHYB5Tg13WM0dd18/X/6BPAX8JlbxxF5HygXlXLEt7yxjGR0RgcvEZEJgB/AL6gqq3x74Wz4WXt8TIReT/QqKol2XJIgTxgJXC7qp4IHCChCsmD6ziF4BfjAmAmMJ4k1RC+ke3rNhAi8lWC6tnfZNslHhEpBP4duCHbLukwGoNDPTAnbn12uC3riEg+QWD4jar+Mdy8O1bMDP82ZssPOAM4T0RqCKrj3klQv18UVo9A9q9nHVCnqi+E6/cTBAufruO7gO2q+rqqdgF/JLi2Pl3HGH1dN6/+j0TkCuD9wCVxUwr74ng0wQ+BsvB/ZzZQKiJH4o9jL0ZjcEhlDuthJ6y7/wWwWVW/F/dW/HzalwMPDbdbDFX9iqrOVtX5BNftcVW9BPg7wVzfkH3HXcAOETkm3HQ2UIFH15GgOuk0ESkMP/eYozfXMY6+rtsa4LLwaZvTgH1x1U/DioisJqjqPE9V4ydLWAN8RETGisgCgkbf9cPtp6rlqjpdVeeH/zt1wMrwXvXmOvZCVUfdC3gvwVMN1cBXs+0TOp1JUGR/BdgQvt5LUKe/FqgC/g8ozrZr6Pt24OFw+SiCf7ptwH3A2Cy7rQBeCq/lg8AU364jcBNQCWwE7gHGZvs6Ar8laAPpIvgCu7Kv6wYIwVN/1UA5wZNX2XLcRlBvH/u/uSMu/VdDxy3Ae7LlmPB+DTAtm9cxlZf1kDYMwzB6MRqrlQzDMIwBsOBgGIZh9MKCg2EYhtELCw6GYRhGLyw4GIZhGL2w4GAYhmH0woKDYRiG0QsLDsaIQkTmi0i7iGwI5234zBDyetZFmmwTXpNecwcMIp9x4XU9FJtvwBi9WHAwRiLVqroCKAKSBodwOIJ+729V/YeBDpRKmjcLqtoeXted2XYxso8FB2Mk8y3g6PDX7nfCX9BbRORXBMNSzBGRB0WkRIJZ166K31lE2sJ9NovIz8I0fxORcWmm+Y/wuE9LMKvbdYmiInKpiKwPXX8iwWx68yWYwew3Yf73hyN4xvb5kgQzxW0UkS/Ebb8snDWsTETuCTfn9uWX4LFARB4SkZdCn2OSpTOMrI/fYS97pfMC5gMbE5fj1qPAaXHbYmMBjSMIGFPj3msL94kAK8JtvwcuTTUNcDLBeD4FwESCMYiuS3A+FvgTkB+u/xi4LMxXgTPC7XfG9gVWEYy1Mx6YAGwimONjKcG4YLGxeYoHOoc4j3yCcZKODtffC9yVJF1NLH97jd6XlRyMNxuvaTCjVozPiUgZwQxhcwhG5kxku6puCJdLCL5sU01zBvCQqnZoMIPfn5LsezbBl/2LIrIhXD8qfG+Hqj4TLv+aYABGwr8PqOoBVW0jGNb7rQTDpN+nqk0AqhqbcSyVc/ggQXD5Q+jxX0AHgIh8PUl6YxSTN3ASwxhRHIgtiMjbCeZOOF1VD4rIOoJf+Il0xi13E5QyBpOmLwS4W1W/ctjGYMa/xJEvBzsSZip+ywlGIf5FgseRBKUKw+jBSg7GSGY/QVVOX0wGmsPAsAQ4LQMOzwAfEJGCcBa/9ydJsxa4UESmA4hIsYjMC9+bKyKnh8sfA54Ol58CPhjO+TAeuCDc9jhwkYhMjeWVhmsDcG6soV5EloXzSawgqBozjB4sOBgjFlXdAzwTNth+J0mSvwJ5IrKZoPH6+SRphurwIsGELa8QzF1cTjAndHyaCuBrwN9E5BXgMSA2ifwW4F9CxynA7eE+pcAvCeZ3eAH4uaq+rKqbgG8AT4TVZfETQw3EnQT/85vDaqV/U1XFgoORBJvPwRhRhFUxD6vq8dl2iSEiE1S1LXzS6EngqvDLfaD95uPBuYjIL4BPqWo0XK8hmHSmKZteRnaxkoMx0ugGJoe/fH3hp6FPKfCHVAKDT6jqlaoajXWCI2h/iGZZy8gyVnIwDMMwemElB8MwDKMXFhwMwzCMXlhwMAzDMHphwcEwDMPohQUHwzAMoxcWHAzDMIxeWHAwDMMwemHBwTAMw+jF/wc3uDDfE8/T8gAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"[training epoch $e_i$]\", fontsize=10)\n",
    "ax.set_ylabel(\"[Classification Error $\\mathcal{L}^{NLL}$]\", fontsize=10)\n",
    "\n",
    "# set plot legend\n",
    "plt.legend(loc=\"upper right\", numpoints=1, fancybox=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title('Training Epochs $e_i$ vs. Classification Error $L^{NLL}$', fontsize=10);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mcgrau/PycharmProjects/SS22_AIML/data/testset\n"
     ]
    }
   ],
   "source": [
    "print(test_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "4232"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSamples = glob.glob(os.path.join(test_directory, \"*.npy\"))\n",
    "len(testSamples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_directory, transform=False):\n",
    "        self.files = glob.glob(os.path.join(test_directory, \"*.npy\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.files[idx]\n",
    "        image = np.load(item).astype(int)\n",
    "        number = int(item.split('/')[-1].split('_')[1].split('.')[0])\n",
    "\n",
    "        if self.transform:\n",
    "          image = transforms.ToTensor()(image).to(torch.float)\n",
    "\n",
    "        return image, number"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "testData = testDataset(test_directory = test_directory, transform = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testData, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RESNET18' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m state_dict_best \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(best_model_name, map_location\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# init pre-trained model class\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m best_model \u001B[38;5;241m=\u001B[39m \u001B[43mRESNET18\u001B[49m()\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# load pre-trained models\u001B[39;00m\n\u001B[1;32m     11\u001B[0m best_model\u001B[38;5;241m.\u001B[39mload_state_dict(state_dict_best)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'RESNET18' is not defined"
     ]
    }
   ],
   "source": [
    "# restore pre-trained model snapshot\n",
    "best_model_name = os.path.join(models_directory, 'cifar10_model_epoch_200.pth')\n",
    "\n",
    "# load state_dict from path\n",
    "state_dict_best = torch.load(best_model_name, map_location=torch.device('cpu'))\n",
    "\n",
    "# init pre-trained model class\n",
    "best_model = RESNET18()\n",
    "\n",
    "# load pre-trained models\n",
    "best_model.load_state_dict(state_dict_best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set model in evaluation mode\n",
    "best_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = []\n",
    "numbers = []\n",
    "\n",
    "for i, (images, nums) in enumerate(test_loader):\n",
    "    # run forward pass through the network\n",
    "    pred = torch.argmax(best_model(images), dim=1)\n",
    "    predictions.append(pred.int().item())\n",
    "    numbers.append(nums.int().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(numbers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predClasses = np.vectorize(idx_to_class.get)(predictions)\n",
    "\n",
    "d = {'test_id': numbers, 'label': predClasses}\n",
    "predData = pd.DataFrame(data = d)\n",
    "predData = predData.sort_values(by=['test_id'])\n",
    "print(predData.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(predData))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predData.to_csv(os.path.join(models_directory,'submission.csv'), index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx_to_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}